{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is Multi-Task Learning Interesting (in Deep Learning)?\n",
    "\n",
    "_Posted: 10/22/2023_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last 2 years or so most of my research has been focused on \"multi-task learning\";\n",
    "my interests in multi-task learning started in multi-lingual learning, which was the topic that I was to work on at the beginning of my PhD.\n",
    "Multi-lingual models had this frustrating quality in that they would often under-perform mono-lingual models of the same capacity; in other words, adding more languages to a model _hurt_ the model's performance on those languages, particularly languages with higher resources.\n",
    "And yet, even still, multi-lingual models had several advantages such as being more space efficient, occasionally improving the performance of lower-resource languages through transfer, and (perhaps most interestingly) allowing for _cross-lingual_ transfer between languages and tasks.\n",
    "\n",
    "A similar phenomena exists in multi-task settings; given two tasks of moderate resource, learning those tasks jointly tends to result in a model which is _worse_ at both tasks than two separate, single-task models.\n",
    "This is not universally true (there are plenty of success stories with multi-task learning), but it is true enough that **negative transfer** is generally regarded as a problem&mdash;and addressing it an open question&mdash;by the multi-task machine learning community.\n",
    "\n",
    "But isn't this just an intuitive consequence of trying to optimize multiple objectives simultaneously?\n",
    "Multi-objective optimization posits that there are _tradeoffs_ which exist between different objectives, characterized by Pareto fronts, which prevent a single system from fully minimizing any single objective while also considering another.\n",
    "So, shouldn't we _expect_ negative transfer in multi-task settings?\n",
    "Isn't it obvious that a bespoke single-task system will generally outperform a more general multi-task system? Jack of all trades, master of none?\n",
    "\n",
    "In this post, I just want to set up a quick argument for why I believe that this may _not_ be the case in Deep Learning, and why multi-task learning is _so interesting_ in this setting.\n",
    "Outline:\n",
    "- MOO and Task Conflict: Trade-offs in minimization\n",
    "- Minimization \\neq Generalization: How you fit the data matters\n",
    "- Underspecification: Single-Task Data may not be enough? Also, in-dist. generalization may not be enough\n",
    "- The Argument for MTL: Is SGD really the best we can do?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Objective Optimization and Task Conlict\n",
    "\n",
    "Multi-Objective Optimization (MOO) is a subset of optimization focused on the minimization of more than one objective simultaneously.\n",
    "Rather than minimizing $\\mathcal{L}(\\theta)$, we are instead interested in minimizing a set of objectives $\\{\\mathcal{L}^1(\\theta), \\ldots, \\mathcal{L}^K(\\theta)\\}$.\n",
    "Given a particular solution space ($\\Theta$), MOO attempts to characterize the tradeoffs that exist between the minimization of each objective via the **pareto front**: a curve that characterizes the _best_ that some $\\theta \\in \\Theta$ can do on $\\mathcal{L}^1$ and $\\mathcal{L}^2$ simultaneously for increasing values of $\\mathcal{L}^1$.\n",
    "The goal of MOO is then typically to find a solution that exists on the pareto front, or perhaps to find a set of solutions which span the pareto front.\n",
    "\n",
    "\n",
    "Multi-task learning is naturally a MOO problem; each task defines a distinct objective and our goal is to find a $\\theta \\in \\Theta$ that minimizes all of these objectives as fairly, and equally, as possible.\n",
    "Indeed, several recent Deep MTL Optimization papers leverage MOO intuitions or theory to motivate their methods, tailoring the gradients such that they are guaranteed to converge to some solution on the pareto front.\n",
    "However, in MTL we are interested in negative transfer, which.\n",
    "What does the Pareto front of the training objectives tell us about negative transfer?\n",
    "In truth, not too much.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimization $\\neq$ Generalization: How The Data Is Fit Matters More Than How _Well_ It Is Fit\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Task Conflict\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underspecification: How The Data Is Fit Matters More Than How _Well_ It Is Fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Argument for Deep MTL\n",
    "\n",
    "Given that multi-task learning seems to fail so often in practice, it is not unreasonable to assume that it may be somewhat doomed (similar to other classical settings).\n",
    "After all, it does seem far-fetched to assume that we should be able to arbitrarily combine tasks together into a single deep neural networks and expect the model to learn.\n",
    "\n",
    "I do not disagree! I think that there is a possibility that multi-task learning in deep neural networks is.\n",
    "However, I will also venture to say that we do not know this _for certain_; it seems entirely plausible to me that we are still missing some fundamental insights when it comes to training deep neural networks on multiple tasks.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
