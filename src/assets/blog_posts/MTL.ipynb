{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is Multi-Task Learning Interesting? (in Deep Learning)\n",
    "\n",
    "_Posted: 10/22/2023_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last 2 years or so most of my research has been focused on \"multi-task learning\";\n",
    "my interests in multi-task learning started in multi-lingual learning, which was the topic that I was to work on at the beginning of my PhD.\n",
    "Multi-lingual models had this frustrating quality in that they would often under-perform mono-lingual models of the same capacity; in other words, adding more languages to a model _hurt_ the model's performance on those languages, particularly languages with higher resources.\n",
    "And yet, even still, multi-lingual models had several advantages such as being more space efficient, occasionally improving the performance of lower-resource languages through transfer, and (perhaps most interestingly) allowing for _cross-lingual_ transfer between languages and tasks.\n",
    "\n",
    "A similar phenomena exists in multi-task settings; given two tasks of moderate resource, learning those tasks jointly tends to result in a model which is _worse_ at both tasks than two separate, single-task models.\n",
    "This is not universally true (there are plenty of success stories with multi-task learning), but it is true enough that **negative transfer** is generally regarded as a problem&mdash;and addressing it an open question&mdash;by the multi-task machine learning community.\n",
    "\n",
    "But isn't this just an intuitive consequence of trying to optimize multiple objectives simultaneously?\n",
    "Multi-objective optimization posits that there are _tradeoffs_ which exist between different objectives, characterized by Pareto fronts, which prevent a single system from fully minimizing any single objective.\n",
    "So, shouldn't we _expect_ negative transfer in multi-task settings?\n",
    "Isn't it obvious that a bespoke single-task system will generally outperform a more general multi-task system? Jack of all trades, master of none?\n",
    "\n",
    "In fact, there are many settings in machine learning where we can _prove_ that a joint model which must fit two very reasonable real-world tasks simultaneously will be worse than two separate models for each task.\n",
    "However, things get a bit more interesting is in _Deep Learning_; in deep learning, nothing is clear. Which means it is not clear that multi-task learning should be beneficial, in general, when training deep neural networks... but it is also not clear that it should be harmful."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Does Multi-Objective Optimization Tell Us About Deep MTL?\n",
    "\n",
    "#### What is MOO? How does it relate to MTL? Finally... why is that not necessarily indicative of negative transfer?\n",
    "\n",
    "Multi-Objective Optimization (MOO) is a subset of optimization focused on the minimization of more than one objective simultaneously.\n",
    "Rather than minimizing $\\mathcal{L}(\\theta)$, we are instead interested in minimizing a set of objectives $\\{\\mathcal{L}^1(\\theta), \\ldots, \\mathcal{L}^K(\\theta)\\}$.\n",
    "Given a particular solution space (in our case, $\\theta$), MOO posits that tradeoffs exist between the minimization of each objective which prevents \n",
    "The goal of MOO is then to find a solution that exists on the pareto front, or perhaps to find a set of solutions which span the pareto front.\n",
    "\n",
    "MTL is a natural MOO problem; each task defines a distinct objective and our goal is to minimize all of these objectives jointly within $\\theta$.\n",
    "Indeed, several recent Deep MTL Optimization papers leverage MOO intuitions or theory to motivate their methods.\n",
    "However, in MTL we are interested in negative transfer, which.\n",
    "What does the Pareto front of the training objectives tell us about negative transfer?\n",
    "In truth, not too much.\n",
    "\n",
    "\n",
    "#### Minimization $\\neq$ Generalization\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Task Conflict\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underspecification: How The Data Is Fit Matters More Than How _Well_ It Is Fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Argument for Deep MTL\n",
    "\n",
    "Given that multi-task learning seems to fail so often in practice, it is not unreasonable to assume that it may be somewhat doomed (similar to other classical settings).\n",
    "After all, it does seem far-fetched to assume that we should be able to arbitrarily combine tasks together into a single deep neural networks and expect the model to learn.\n",
    "\n",
    "I do not disagree! I think that there is a possibility that multi-task learning in deep neural networks is.\n",
    "However, I will also venture to say that we do not know this _for certain_; it seems entirely plausible to me that we are still missing some fundamental insights when it comes to training deep neural networks on multiple tasks.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
