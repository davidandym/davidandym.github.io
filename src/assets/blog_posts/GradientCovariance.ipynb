{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics of Gradient Covariance and Temperature\n",
    "\n",
    "Recently, my research has shifted towards studying optimization in deep learning, and in particular I've been interested in this notion of the _temperature_ of SGD, i.e. how much *noise* we incur in our estimation of the true gradient, given the gradient of only a single example, or perhaps a small batch.\n",
    "\n",
    "\n",
    "### What _is_ gradient covariance?\n",
    "\n",
    "To begin with, gradient covariance is defined for a specific function and dataset. The function, which we'll call $f_\\theta$, must be differentiable and we'll assume that it's parameterized by $\\theta \\in \\mathbb{R}^d$.\n",
    "The dataset $\\mathcal{D}$ is composed of $N$ examples $x_1, x_2, \\ldots, x_N$, all of which may be passed into $f_\\theta(x_i)$. Finally, we will assume that we have some differentiable loss function $\\mathcal{L}(x, \\theta)$ which measure the error of $f_\\theta$ on example $x$.\n",
    "\n",
    "We define $G(x) = \\nabla_\\theta \\mathcal{L}(x, \\theta)$ to be the gradient of $x$ given parameters $\\theta$. In optimization, we are often interested in the average gradient over the entire dataset, which we'll call the **true gradient** $G_T$\n",
    "$$\n",
    "G_T = \\frac{1}{N}\\sum_{x\\in\\mathcal{D}}G(x)\n",
    "$$\n",
    "\n",
    "However, the true gradient can be expensive to compute since it involves computing the gradient over the entire dataset. So, often we instead decide to _approximate it_ by approximating $G_T$.\n",
    "We start by treating the gradient as a discrete random variable, which we'll call $G$. All possible values of $G$ can be determined by running over all possible $x\\in\\mathcal{D}$ and computing $G(x)$.\n",
    "Because we often only consider uniform distributions over our dataset (i.e. all examples are weighted equally), the **expected value** of $G$ is\n",
    "$$\n",
    "\\mathbb{E}_{x\\sim\\mathcal{D}}\\big[G\\big] = \\frac{1}{N} \\sum_{x\\in\\mathcal{D}} G(x) = G_T\n",
    "$$\n",
    "The **covariance matrix** of $G$ is\n",
    "$$\n",
    "\\Sigma(G) = \\frac{1}{N}\\sum_{x\\in\\mathcal{D}}\\big[(G(x) - G_T)(G(x) - G_T)^T \\big]\n",
    "$$\n",
    "$\\Sigma(G)$ is a $d\\times d$ matrix - the diagonals $\\Sigma_{i,i}$ represent the independent variance of $\\theta_i$, while $\\Sigma{i,j}$ represents the covariance of $\\theta_i$ and $\\theta_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Demonstration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Eigenvectors and Eigenvalues\n",
    "\n",
    "There are a couple of important facts to note about the Eigenvectors and Eigenvalues of a covariance matrix.\n",
    "\n",
    "The first, and most well-known, is that the eigenvectors point in the directions of highest variance while remaining orthogonal to each other.\n",
    "\n",
    "Another interesting fact is that the sum of the independent variances of each parameter $\\theta_i$ is actually equal to the sum of the eigenvalues of the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring \"Noise\"\n",
    "\n",
    "Given these facts about.\n",
    "\n",
    "Say we wanted to compress the covariance matrix down to a single value, which determined how noisy the dataset is compared to.\n",
    "\n",
    "Trace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Effect of Batch-Size on Covariance\n",
    "\n",
    "Increasing the batch-size decreases the noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Gradient Norm\n",
    "\n",
    "Expected gradient norm is large compared to norm of expected gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature of SGD\n",
    "\n",
    "The _temperature_ of SGD is often defined as the ratio between the learning rate $\\epsilon$ and the batch-size $B$, i.e.\n",
    "$$\n",
    "T = \\frac{\\epsilon}{B}\n",
    "$$\n",
    "these two hyperparameters together can effect the variance of $G$ - increasing the batch-size decreases the variance, as we have already seen. And the learning rate scales the variance of $G$ by a factor of $\\sqrt{\\epsilon}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation to the FIM\n",
    "\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation to the Hessian\n",
    "\n",
    "??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
