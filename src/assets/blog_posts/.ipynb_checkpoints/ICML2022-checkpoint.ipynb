{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Take-Aways from ICML 2022 (Draft)\n",
    "\n",
    "ICML 2022 was my first in-person conference since... 2018. It's been nearly **4 years** since I have walked through a real poster-session, gotten beers with researchers that I follow on twitter but never met before, and sat in a big lobby working on items unrelated to the conference. I want to take some time after the conference to ruminate on how I feel about my experience, and also touch on some papers that I really enjoyed.\n",
    "\n",
    "Firstly, I thoroughly enjoyed ICML 2022 - it is the first machine learning conference I have ever attended (in-person) and in general I am very happy I came. I had a lot of fun chatting with researchers of various levels and making some new friends. My interests have gradually shifted away from NLP towards more general ML problems, and I'm excited that I was able to start getting to know the ML community a bit better. I have a few takeaways that I want to jot down while they're still fresh in my mind. The TL;DR of these take-aways is that I think conferences like ICML are simply too big, and need to make a more conscious effort to get people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Person Conferences feel really important to a PhD\n",
    "\n",
    "My first take-away is that my PhD has definitely suffered from not having in-person conferences for the last 2 years.\n",
    "There's not much that's really actionable on this take-away - \n",
    "_c'est la vie_, and at the end of the day I'm extremely lucky that my life, both inside and outside of work, was left relatively unnaffected by the pandemic.\n",
    "At the same time, it's pretty clear to me that in-person interactions are nearly irrepleacable.\n",
    "I met a few people whose research interests directly aligned with mine, and not only.\n",
    "In some cases, emails were exchanged and I can hope that.\n",
    "\n",
    "In 2 years of virtual conferences, such an interaction never happened for me. I will admit that towards the end of those 2 years my motivation to go to online social events at conferences was abysmally low, but even towards the beginning when I was excited by GatherTown poster sessions and.\n",
    "\n",
    "I'm not sure what the secret ingredient is, and if it can be replicated in an online setting, but if it can it hasn't been yet.\n",
    "I'm so lucky that I'm in a position where, now that conferences are starting again, I can rest reasonably assured that I will be able to attend at least one or two a year. Not every PhD student has the same gaurantees and it's a real shame how limiting it seems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too many talks, not enough posters\n",
    "\n",
    "My second take-away is that ICML seems to have a sincere focus on spotlight talks - the entire day is comprised mainly of 5-minute spotlight talks with a couple 15-minute oral talks spread throughout, and poster sessions are relegated to the end of the day, from about 6:30pm-8:30pm. I cannot stress enough how much I _hate_ this design - most social events, industry or otherwise, start around 6:30-7pm. This means that you have to choose between going to social events or sticking around in a poster session where most presenters are trying to leave so they can go to social events. **Social events and poster sessions are the best part of a conference!** This is not a problem for just one day - all 3 days of the main conference I had to choose between attending poster sessions for more than 30 minutes, or showing up very late to one social event or another. Most of the day is comprised of 5-minute talks that are very hard to follow (because of the time constraint) unless you're already well-tuned to that area's main ideas and jargon, and a are often just pre-recorded videos - as a result, I spent most of the day hanging outside in the lobby talking to people while waiting for poster sessions to start. I'm know not the only one who had this issue either: see [Hal](https://twitter.com/haldaume3/status/1549452798877728768), [Claas](https://twitter.com/c_voelcker/status/1550504580412219393), and [Micah](https://twitter.com/micahgoldblum/status/1551568956598673410)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are ICML et al. too big?\n",
    "\n",
    "My first take-away is that this conference is _extremely_ broad. My prior conference experience with \\*ACL conferences had primed me for an experience where I can approach nearly anybody, any talk, or any poster and usually come away with a good idea of how what was discussed is related to my research ideas or the ideas of the field in general;\n",
    "this was not my experience at ICML.\n",
    "I saw [Dan Roy](https://twitter.com/roydanroy/status/1550492693817597952?s=20&t=POQcGlmPZZsddtXbCNlzwQ) mention recently that conferences like NeurIPS and ICML are really 20 conferences wrapped up in 1 -\n",
    "it's hard to disagree.\n",
    "In many ways this is very fun, since it exposes you to a lot of people you wouldn't normally meet and a lot of ideas that you wouldn't normally come across...\n",
    "However, this isn't _that_ helpful for your research.\n",
    "Most people will understand what you do at a very high level, but they won't have a very strong opinion on your most recent ideas or results, and vice versa; it's simply hard to have a very deep conversation about ideas when there is not a lot of common ground to begin with.\n",
    "I actually found it _very hard_ to run into people who are working on similar things as me -\n",
    "About 9 in 10 people that I met were working in totally different areas than me, be it causal learning, reinforcement learning, theoretical optimization, probabilistic models... the list goes on.\n",
    "As a result, while I met a lot of people and enjoyed talking to them about life, traveling, and the weather, _I didn't have a lot of discussions about my research_... and while I certainly liked the people I met and I hope I run into them again soon, the very candid part of me suggests that this is not the primary function of conferences.\n",
    "\n",
    "Finally, I'll just note that there is something to be said for smaller, more focused conferences.\n",
    "Compared to this conference, \\*ACL is a very small, and tight-knit community.\n",
    "I think this has implications for how I interact with people, e.g. talking about research versus talking about the weather.\n",
    "I think this is exacerbated by the fact that ICML didn't really make much of an effort to gather researchers in similar areas together for the purpose of discussion; over the pandemic, \\*ACL conferences implemented \"Birds of a Feather\" rooms, designed to simply get researchers interested in similar topics into a (zoom) room to have a discussion that was led by a moderator of sorts.\n",
    "This likely needs some tuning to in-person sessions, but I think it's a good idea to meet people who are at the conference for the same reasons you are.\n",
    "Instead, at ICML, people with similar interests (that you don't already know) can be found in the spotlight sessions (during which you're not supposed to talk) and poster sessions (...did I mention the deal with poster sessions?).\n",
    "Most of the social interactions are instead offloaded to industry events, which are not filtered by a person's research focus.\n",
    "I'll simply end this by saying that, despite the fact that I very much enjoyed attending ICML and I hope to attend many more ML conferences in the near future... I wonder if they aren't getting too big for their own good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so after all these negative take-aways, \n",
    "\n",
    "In short, my main takeaway from ICML is that it either needs to shrink by splitting up the.\n",
    "It's interesting that conferences like ICML, NeurIPS, and ICLR are some of the most prestigous conferences in the field and yet are possibly the worst designed to foster deep, meaningful conversations about any specific area, especially amongst strangers.\n",
    "\n",
    "However, this must all be hedged on the fact that I'm a first-time attendee. I don't yet know a lot of people who are working in my direction, since I switched during covid and haven't had the chance to meet anyone since then. I do not doubt that over time, as I meet more people who work in my area, I will eventually be able to recognize people at these conferences who. Still, I think I had higher expectations for the number of people I would meet.\n",
    "\n",
    "All in all, I had a very good experience here. I met a lot of very cool people, had a lot of fun conversations, and yes I even got a few ideas about my own research from it. People are generally very friendly - if you say hi to someone they will say hi back and you can usually work from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Paper Highlights from ICML 2022\n",
    "\n",
    "Okay, now that I've had my speil, I want to briefly highlight some papers from the conference that I think are worth checking out. Of course, these papers come with the caveat that they are papers that are related to my interests or current research. ICML is a very broad conference (did I mention that?) and I'm sure there was lots of incredible work on RL theory... you won't find that here. Additionally, I'm going to skip over Outstanding Paper winners, since it's very likely you will find those on your own...\n",
    "\n",
    ">_Briefly, regarding outstanding paper awards, my favorite was easily [Bayesian Model Selection, the Marginal Likelihood, and Generalization](https://proceedings.mlr.press/v162/lotfi22a.html) - it's the most relevant to my own research and\n",
    "[Sanae Lotfi](https://twitter.com/LotfiSanae) gave a great talk, despite concurrently having to deal with some twitter drama.\n",
    "You should read the paper if you have the chance, but there is also a very good [thread on the paper](https://twitter.com/jxbz/status/1550495966213677056) by Jeremy Bernstein._\n",
    "\n",
    "Okay, so for the rest of the papers, I'm going to focus on papers which _broadly_ fall under the category \"**Understanding Deep Learning**\".\n",
    "This is a category of papers that I'm always looking for at machine learning conferences, and includes papers which highlight some empirical phenomena in neural networks, or papers which connect some empirical findings to theoretical results, in a way that expands our _understanding_ of how these complex models really learn.\n",
    "I've attempted to provide something of a sub-grouping to the set of papers, but ultimately I feel like many papers blur across sub-groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    ">_The first couple papers here touch on the rate at which different features are learned in a neural network. As someone who works in multi-task learning, I obviously think this area of study is really interesting and can reveal a lot about **how** these models might learn distinct functions simultaneously._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [Multirate Training of Neural Networks](https://proceedings.mlr.press/v162/vlaar22b.html)\n",
    "_Tiffany Vlaar · Benedict Leimkuhler_\n",
    "\n",
    "\n",
    "This paper studies the effects of multi-rate training - training a neural network with different learning rates for different parameters. Namely, they split up a network into _slow_ and _fast_ parameters; the _slow_ parameters are updated only every $k$ steps, whereas the _fast_ parameters are updated every step (pictured below).\n",
    "What is the point of this?\n",
    "The paper opens with a simple example from [Li et al., 2020](https://arxiv.org/pdf/1907.04595.pdf) - a $7\\times7$ patch of noise is added to the center of some CIFAR-10 training samples.\n",
    "It's well-established that, all other hyperparameters fixed, a model with a small learning rate will memorize the patches in the training data at the cost of performance on clean images, but a model with a high learning rate will instead ignore the patches -\n",
    "here the authors show that a _multi-rate_ model can **simultaneously learn both**.\n",
    "This has some important theoretical implications regarding neural network memorization, capacity, and learning rates.\n",
    "\n",
    "![](blog_figs/icml2022/multirate.png)\n",
    "\n",
    "In addition, the authors show that multi-rate training can be used to significantly speed up fine-tuning pre-trained models on downstream tasks without affecting performance, by treating only the last layer as the \"fast\" parameters.\n",
    "Finally, the authors combine multi-rate training with dropout in a novel regularization scheme and show that it can improve performance (rather drastically) over vanilla dropout, suggesting some benefit to making sure the \"dropped\" parameters are updated before being re-activated.\n",
    "Check out the paper for convergence analysis and discussions of techniques like _linear drift_.\n",
    "\n",
    "#### TL;DR\n",
    "\n",
    "Simply training different parameters of a model at different rates has important theoretical implications, by changing what a model can simultaneously learn, as well as several practical implications, e.g. efficient transfer learning and a stronger forms of dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. [Multi-scale Feature Learning Dynamics: Insights for Double Descent](https://proceedings.mlr.press/v162/pezeshki22a.html)\n",
    "_Mohammad Pezeshki · Amartya Mitra · Yoshua Bengio · Guillaume Lajoie_\n",
    "\n",
    "\n",
    "#### Short Summary\n",
    "\n",
    "\n",
    "\n",
    "_Epoch double descent_ is the phenomena of _training epochs_ mirroring the double descent curves commonly associated with _model complexity_ in deep learning.\n",
    "This work is interested in studying epoch double descent via linear models which are _complex_ enough to exhibit epoch double descent, but _simple_ enough to be analyzed directly.\n",
    "To do this the authors use a teacher-student model setup to create a training regime where a student model learns to mimic a _noisy_ teacher while being fed _modulated_ inputs (shown below). The modulation matrix $F$ determines which features are more \"accessible\" to the student model during learning, and which are less. \n",
    "\n",
    "![](blog_figs/icml2022/multiscale-feature-2.png)\n",
    "\n",
    "Under this setting, a model trained with SGD has generalization error that can be decomposed into two _macroscopic_ terms, which are composed of either _fast_ features (more accessible) or _slow_ features (less accessible).\n",
    "The _dynamics_ of this model can then be described in terms of these macroscopic variables, where double-descent emerges analytically.\n",
    "This yields the following result, which is pictured below: epoch double descent occurs in models because there exist \"fast\" features and \"slow\" features; Fast features are learned quickly but result in overfitting when solely relied on; slow features are learned much slower but are necessary to generalize well; when they are learned jointly the _epoch_ double-descent curve arises.\n",
    "Finally, the authors rely on a connection between regularization strength and the accessibility of features to show that ResNet18 models trained on CIFAR-10 behave similarly to the student-teachear model setup for different levels of regularization / modulation, corroborating their analytical results to some extent.\n",
    "\n",
    "![](blog_figs/icml2022/multiscale-feature.png)\n",
    "\n",
    "#### TL;DR\n",
    "\n",
    "Analysis of a simple linear model which exhibits epoch double descent suggests that epoch double descent occurs due to different features being learned at different rates - as fast features begin to overfit, slow features are learned which further decreases the loss.\n",
    "Moreover, despite the simplicity of the analytical linear model, it can be shown to mirror the effects of modern neural networks with regularization in practice, corroborating the proposed model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    ">_The next set of papers focuses on the relationship between the training data and the model. Specifically, the first couple of papers are interested in the relationship between the training data and test-time predictions; the final paper of this group is concered with symmetries between the model architecture and the data distribution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. [The Dual Form of Neural Networks Revisited: ...](https://proceedings.mlr.press/v162/irie22a.html)\n",
    "#### _Kazuki Irie · Robert Cordas · Jürgen Schmidhuber_\n",
    "\n",
    "#### Short Summary\n",
    "\n",
    "Do neural networks make predictions by interpolating memorized inputs?\n",
    "Yes.\n",
    "Just kidding.\n",
    "This work studies this question by constructing the _linear_ components of a neural network (i.e. prior to non-linear activations) in their _dual form_.\n",
    "The dual form of a linear layer trained with SGD acts as a _key-value attention mechanism_ over the entire training sequence, pictured below.\n",
    "Specifically, the outputs of a trained model can be seen as the output of the _initial linear weights_ ($W_0$) added to the outputs of an attention mechanism which computes similarities based on the input to the layer and all previously seen inputs.\n",
    "The _values_ of the attention mechanism are the previous _error signals_ ($e_t$ below) associated with those inputs, which are essentially the gradient of the _output_ times the learning rate ($e_t = -\\eta \\nabla_y \\mathcal{L}_t$).\n",
    "\n",
    "![](blog_figs/icml2022/dualform.png)\n",
    "\n",
    "The above result is not new - the dual form of linear layers has been known for quite some time - however, it is not often studied due to the significant space and time requirements;\n",
    "[note that there are works that _have_ studied this dual form, however!](https://twitter.com/EmtiyazKhan/status/1550632006660542465).\n",
    "In this work the authors propose to leverage relatively small models and tasks (e.g. feed-forward nets on MNIST or small LSTMs on WikiText-2) to be able to directly store each layer's history and directly compute the dual form during test-time.\n",
    "The authors then highlight how interpreting the linear layers of models as an attention mechanism over the training history can be leveraged to interpret neural network outputs based on which training examples recieve the highest attention.\n",
    "They show that catastrophic forgetting in continual learning can be explained by _attention interference_, where prior task inputs pay too much attention to the more recent task's training history, resulting in a degradation in performance.\n",
    "In addition, the authors use this attention mechanism to show how multi-task models learn to share more information in higher layers by more evenly distributing attention values across different tasks.\n",
    "There's a few more examples of model interpretability are in the paper!\n",
    "\n",
    "\n",
    "#### TL;DR\n",
    "\n",
    "The linear component of neural networks (before non-linear activations) can be expressed, in it's dual form, as an attention mechanism over all past training experiences.\n",
    "Studying networks in this way is extremely costly in terms of memory requirements, but allows for model outputs to be interpreted via the prior training examples which have the highest weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. [Datamodels: Understanding Predictions with Data and Data with Predictions](https://proceedings.mlr.press/v162/ilyas22a.html)\n",
    "#### _Andrew Ilyas · Sung Min (Sam) Park · Logan Engstrom · Guillaume Leclerc · Aleksander Madry_\n",
    "\n",
    "#### Short Summary\n",
    "\n",
    "This paper introduces the concept of a **Datamodel** - a function which models the relationship between the training data of a model and it's output _after training_ on that data.\n",
    "Formally, let $f_{\\mathcal{A}}(x, S)$ be the output of a model on example $x$ after training with algorithm $\\mathcal{A}$ on training set $S$.\n",
    "For a neural network, such a function $f$ is difficult to analyze as it involves optimizing a network with e.g. SGD.\n",
    "However, this work shows that a simple _surrogate_ function $g(S)$ can be used to approximate $f$ given enough examples of $(S', f(S')$ on e.g. CIFAR-10, where $S' \\subset S$.\n",
    "In particular, this work shows that a _linear_ data model i.e. $g_{\\theta_x}(S') = \\mathbf{1}_{S'} \\cdot \\theta_x$ suffices to accurately predict neural network behavior after a sufficient amount of examples - in other words, the output of $f_\\mathcal{A}(x, S')$ can be approximated by a sum of learned weights for each example in $S'$\n",
    "(_this is relatively shocking to me_).\n",
    "\n",
    "Such a simple function of how the training data relates to model outputs has a myriad of applications with respect to model interpretability.\n",
    "For example, the authors show that datamodels can be used to efficiently identify the _minimal subset_ of the total training set for which an SGD-trained model's prediction will flip, exposing brittle examples which rely on a tiny subset of training data for accurate prediction, along with other counterfactual artifacts.\n",
    "Another application (shown below) is quickly identifying train-test leakage - train images with high weights in a datamodel are often very similar to the test image and the authors use crowdsourced workers to verify this leakage. \n",
    "There are many more examples of applications using datamodels in the paper and they're all very interesting - check it out!\n",
    "\n",
    "![](blog_figs/icml2022/datamodels.png)\n",
    "\n",
    "#### TL;DR\n",
    "\n",
    "Given enough examples of network behavior, a very simple linear function can learn the relationship between individual datapoints in a training set and a neural network's predictions on a fixed test point (after training with SGD). Such a \"datamodel\" is very interpretable and can identify train-test leakage and counterfactual datapoints, among several other applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. [Synergy and Symmetry in Deep Learning: ...](https://proceedings.mlr.press/v162/xiao22a.html)\n",
    "#### _Lechao Xiao · Jeffrey Pennington_\n",
    "\n",
    "#### Short Summary\n",
    "\n",
    "The _curse of dimensionality_ suggests that learning in high-dimensions is infeasible as the number of required training samples grows exponentially with the dimension of the data.\n",
    "Despite this theoretical limitation, modern datasets are efficiently learnable by neural networks, suggesting certain synergies exist between the inference algorithm $\\mathcal{I}$, the model class $\\mathcal{M}$, and the data $\\mathcal{D}$.\n",
    "To study these synergies, the authors propose a set of transformations to a dataset of images (pictured below) - many of these transformations destroy many spatial properties that (to us) encode the semantic properties of the image.\n",
    "Crucially however, these transformations _preserve_ certain notions of distance between each image in the dataset - to a model that does not leverage such spatial properties, the transformations make no difference to how the model learns.\n",
    "\n",
    "![](blog_figs/icml2022/synergy-1.png)\n",
    "\n",
    "To study the synergies between model architectures and data distributions, the authors study a set of models which expose a heirarchy of inductive biases (fully-connect networks $\\rightarrow$ locally connect networks $\\rightarrow$ weight-sharing $\\rightarrow$ translation invariance).\n",
    "and train these networks using 3 different inference algorithms (The NTK Kernel, SGD with a small learning rate, and SGD with a large learning rate and L2 regularization).\n",
    "The authors show that models with few inductive biases (e.g. Fully Connected Networks, or FCN below) remain invariant to the transformations on input space.\n",
    "However, models which leverage inductive biases such as translation invariance (GAP models, for instance), are able to leverage .\n",
    "\n",
    "![](blog_figs/icml2022/synergy-2.png)\n",
    "\n",
    "These results clearly demonstrate \n",
    "\n",
    "#### TL;DR\n",
    "\n",
    "This work presents a very clever study on the symmetries between inductive biases in the model class and transformations to the data distribution. They find that inductive biases such as translation invariance clearly leverage spatial structure in the data, whereas models with fewer inductive biases such as fully-connect networks, do not. These symmetries can be strengthened with more data, actually.\n",
    "**This paper took me a while to wrap my head around, but I _really_ like it - it might be my favorite paper from the conference.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    ">_The final set of papers in my summary instead focus on optimization and generalization - in particular, understanding how our optimization decisions affect generalization._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. [Towards understanding how momentum improves generalization in deep learning](https://proceedings.mlr.press/v162/jelassi22a.html)\n",
    "#### _Samy Jelassi · Yuanzhi Li_\n",
    "\n",
    "\n",
    "#### Short Summary\n",
    "\n",
    "Why does momentum improve generalization in deep learning?\n",
    "In practice, momentum is almost a given - it is nearly always a good idea to use momentum (often with a heavy coefficient) when training a deep neural network.\n",
    "But in theory, it still is not clear why momentum is _so useful_ for generalization.\n",
    "To study this question, the authors of this paper first put forth a set of experiments showing (a) momentum helps generalization even in _full-batch_ gradient descent, suggesting that momentum does not only help generalization by reducing SGD noise and (b) there exist settings where momentum actually _harms_ performance with deep neural networks.\n",
    "Motivated by these empirical results, the authors attempt to theoretically analyze why momentum helps with deep learning.\n",
    "\n",
    "To do this they construct a binary classification setting where the inputs consist of multiple _patches_ - only one patch per input is predictive of the true label, and it's margin is either large (with high probability) or small (with low probability). The rest of the patches are sampled from noise, and are not predictive of the true label.\n",
    "They model this dataset with a convolutional network with a cubic activation and treat the problem as logistic regression (with classes $-1$ and $1$).\n",
    "The authors prove that, in this setup, a model trained with gradient descent will first learn the examples with large margins, which have the largest gradients - once the gradients of large-margin examples gets small enough, the model will begin to learn the small-margin examples.\n",
    "However, because the gradient from the small margin patches is so small, gradient descent will memorize the examples via their noisy patches rather than continue to learn the half-space predictor.\n",
    "Adding momentum **mitigates** this effect by keeping the gradient correlated with the large-margin examples while learning the small-margin examples - the causes the model to instead memorize the small-margin examples via their predictive patch keeping the model consistent in both phases.\n",
    "\n",
    "\n",
    "#### TL;DR\n",
    "\n",
    "The authors provide a theoretical treatment of momentum in gradient descent - at a high level, their main result suggests that gradient descent first learns high-margin (easy) data, and then memorizes small-margin (difficult) data points. With momentum, the model is forced to memorize small-margin data in a way that is _consistent_ with the previously learned (easy) data, and therefore learns to generalize on small-margin data rather than overfit to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. [Adaptive Inertia: Disentangling the Effects of Adaptive Learning Rate and Momentum](https://proceedings.mlr.press/v162/xie22d.html)\n",
    "\n",
    "#### Zeke Xie · Xinrui Wang · Huishuai Zhang · Issei Sato · Masashi Sugiyama\n",
    "\n",
    "#### Short Summary\n",
    "\n",
    "\n",
    "Adam is probably the most popular optimizer in modern deep learning - however, in many vision problems Adam converges much faster than SGD but often generalizes worse.\n",
    "_Why is this?_\n",
    "\n",
    "\n",
    "https://icml.cc/virtual/2022/oral/17066\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. [Penalizing Gradient Norm for Efficiently Improving Generalization in Deep Learning](https://proceedings.mlr.press/v162/zhao22i.html)\n",
    "\n",
    "#### Yang Zhao · Hao Zhang · Xiuyuan Hu\n",
    "\n",
    "#### Short Summary\n",
    "\n",
    "Several common intuitions around why neural networks generalize focus on some form of _flatness_ in the loss landscape, e.g. that perturbations to the parameters do not significantly change the model's training loss.\n",
    "Given this intuition, it would be nice to optimize directly for flat regions of the loss landscape by jointly minimizing the objective _and_ say the spectrum of the Hessian or the norm of the gradient.\n",
    "Unfortunately, such objectives typically require the computation of the Hessian itself, which is infeasible to compute for modern neural networks.\n",
    "\n",
    "\n",
    "#### TL;DR\n",
    "This work proposes an approximation to the gradient of the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ICML Debate: Science or Engineering?\n",
    "\n",
    "This year the last social session of the conference featured a debate over whether science or engineering would drive progress towards achieving AI.\n",
    "The debate was centered around the question **\"Will progress towards achieving AI be mostly driven by engineering or science?\"**\n",
    "I watched it and I have some thoughts, but I'm just going to summarize the various positions first and then list my thoughts out afterwards.\n",
    "\n",
    "The debate was in the British Parlaimentary style, which essentially boils down to 4 people for each \"side\" who each get to make a 5-7 minute argument.\n",
    "It starts with the \"leader\" of the proposition team, which in this case was the team advocating for engineering, and they are followed by the \"leader\" of the opposition team, which in this case was the team advocating for science.\n",
    "The next in line repeat the pattern, and so on.\n",
    "This means the later speakers have the opportunity to address arguments made during the debate, whereas the opening arguments are largely prepared speeches.\n",
    "The only other thing worth noting: when the member of one party is speaking, a member of another party can raise a \"point of information\" wherein they have about 15 seconds to raise a relevant point or ask a question to the current speaker.\n",
    "The speaker can actually _decline_ the point of interest, and continue talking - as far as I could tell, however, only one speaker in this debate actually declined points of interest.\n",
    "\n",
    "Okay, so now I'm going to jump into the debate - my goal here is to simply summarize the main points of each speaker, in the order they presented, and hopefully not do such a poor job of it that I get an angry email in a few weeks.\n",
    "\n",
    "\n",
    "#### [Sella Nevo](https://research.google/people/SellaNevo/) (Leader of Proposition)\n",
    "\n",
    "Science is about understanding deep truths, and letting our understanding drive progress.\n",
    "Engineering is more aobut building tools and infrastructure so we can see what does and doesn't work.\n",
    "Both contribute, but engineering will be the major driver.\n",
    "Engineering is the driver for the ability to use data.\n",
    "Engineering increases the amount of computational power that we have.\n",
    "Engineering builds research infrastructure, e.g. pytorch & tf, faster training, etc., and even programming languages.\n",
    "Engineering builds deployment of AI systems.\n",
    "\n",
    "Finally, they argue that AI actually drives research in AI as well.\n",
    "- Data is the sole largest driver of AI progress today.\n",
    "- The main bottleneck is no longer conceptual breakthroughs, not data pipelines.\n",
    "- Open AI's scaling laws - progress is due to increases in data and computation\n",
    "- computation and data availability has been rising rapidly\n",
    "- We really don't understand how deep learning systems work, theory is way behind. Everything is empirical now.\n",
    "- Even algorithmic progress engineering has been a more significant driver than science.\n",
    "\n",
    "\n",
    "#### [Kyunghyun Cho](https://kyunghyuncho.me/) (Leader of Opposition)\n",
    "\n",
    ">_Professor Cho wrote a post capturing his speech and thoughts [here.](https://kyunghyuncho.me/my-opening-statement-at-the-icml-2022-debate/)_\n",
    "\n",
    "Recent progress would seem to paint the picture that impressive feats of engineering (such as that enabling massive scaling which has achieved sincerely impressive progress in AI).\n",
    "However, Cho argues that without science we would not be where we are today, which he stresses is \"not even close to true AI\".\n",
    "To do this, he highlights that many of the SOTA language models today are all built on a few core concepts - the basis of next word prediction can be traced all the way back to Claud Shannon in the 1950's.\n",
    "This same idea has been repurposed over and over.\n",
    "Cho next turns to many \"tricks\" of deep learning that have enabled significant progress:\n",
    "- ReLU activations, or non-saturating activations. These came from 2 research labs in 2010, whose focus was _not_ on engineering or large-scale models?\n",
    "- How could engineering have reached this? With extensive hyper-parameter search and tuning we may have found a particular initialization that would have made sigmoid activations work, but we may also have given up on neural networks before we reached that point.\n",
    "- Shortcut connections took decades to come up with to address vanishing gradients - it started with mathematical analysis in early 90s and some empirical analysis in later decades and finally some proposals of which some were successful.\n",
    "It was science that has put us on this path so that engineering could push us forward.\n",
    "Soon, we will once again reach a crossroads on this path and science will tell us where to go next, not engineering.\n",
    "\n",
    "#### [François Charton](https://twitter.com/f_charton?lang=en) (Deputy Leader of the Proposition)\n",
    "\n",
    "It makes a lot of sense to say that every progress _uses_ science but what is the driver?\n",
    "Many progress in our field is preceded and made possible by advances in engineering.\n",
    "Back in the 80s when NNs became fashionable again because of backprop - backprop may be science, but it's a very simple scientific idea that made it possible to run neural networks _on the computers we had back then_.\n",
    "The GPU, and more specifically libraries to leverage GPUs for tensor calculations - were the libraries for GPUs not around, it would have been extremely difficult to make progress.\n",
    "\n",
    "Many big things like dropout, relu, batchnorm, all the way up to transformers had a strong engineering field - many of these early works proposed explanations that are actually no longer valid or held. Nevertheless, we still use these technologies because the work, regardless of their theoretical validity.\n",
    "\n",
    "You always start with an engineering change that makes experimentation possible and then you can assign science to do things.\n",
    "It's the same story with LLMs - we can experiment with them now and we have new tricks etc. to train these massive models and now science gets to understand them.\n",
    "But to build them, we first need engineers.\n",
    "Historically engineering has been the catalyst for experiments which allows science to intervene.\n",
    "Will this pattern continue in the future?\n",
    "\n",
    "Here Cho raises a PoI: \"data collected and experiments run without purpose are useless - science gives them that purpose.\"\n",
    "Francois concedes this point but argues that, in LLMs, quantity dominates over quality - and so, being able to prepare this data etc. requires engineers.\n",
    "\n",
    "Cont. prior point - our papers are engineering driven and recruitment focus on engineering questions and we've become more and more a community of engineers who do some science.\n",
    "\n",
    "#### [Ida Momennejad](https://www.momen-nejad.org/) (Deputy Leader of the Opposition)\n",
    "\n",
    "3 points.\n",
    "- The carbon footpring of training GPT-3 is the equivalent of driving to the moon and back.\n",
    "- Pruning studies show that our current training procedure is extremely inefficient.\n",
    "    - Deep learning needs a pre-frontal cortex. We need an energy efficient solution.\n",
    "    - We don't need to all be inspired by brains, but we should be much smarter about how we're scaling so we don't destroy the planet.\n",
    "- Ecological intelligence. We exist in ecosystems, other entities, and species. We should be inspired by multi-agent ecologies. When we look at collective behavior we can learn to devise better and more efficient structures.\n",
    "- Reward is not enough - the world doesn't come with tags of rewards. There is an interaction between the environment.\n",
    " If AI keeps expanding with the current approaches it is not in accordance with the ecosystem.\n",
    " \n",
    "Doing amateur science is not not doing science, it is doing bad science.\n",
    "\n",
    "\"We solved working memory, \n",
    "\n",
    "Sella raises a PoI at this point: \"It sounds like you're saying that you are either doing science or randomly trying things. Is engineering really just \"randomly trying things\"?\"\n",
    "Ida responds: \"Engineering that does not randomly try things are guided by hypotheses rooted in science. The objective functions of engineering are provided by either science, or the social / moral needs it's trying to serve.\"\n",
    "\n",
    "Finally, the question is about \"turning point progress\" - .\n",
    "\n",
    "To summarize:\n",
    "- a high carbon footprint, scale is not enough to sustainably develop intelligence. Without a scientific hypotheses, we will burn the plant simple trying to scale.\n",
    "- if we look at natural intelligence, e.g. brains or collective behavior or homeostatic systems, we can make better and more efficient architectures.\n",
    "- doing amateur science is okay but you are still doing science when you pose a hypothesis. The main turning points that allow significant progress came from science.\n",
    "\n",
    "#### [Maya Gupta](https://www.mayagupta.org/) (Member of Proposition)\n",
    "\n",
    "Starts by rebutting some of Ida's points.\n",
    "\n",
    "AI is very expensive to traing - this is an engineering problem, to make things train faster.\n",
    "\n",
    "We should be inspired by brains - while brains are energy efficient, they might not be the best way to do things, e.g. calculators. Birds vs. planes. etc.\n",
    "\n",
    "Lastly, in nature things are engineered in many different ways. We can be inspired by the behavior of natural intelligence without needing to copy it's internals.\n",
    "\n",
    "Here Ida raises a POI: \"I'm not arguing that we need to copy the brain, just that we can be inspired by it's efficiency.\"\n",
    "\n",
    "Science is necessary to work with humans - we can get away with interacting with humans without necessaraily needing more science.\n",
    "\n",
    "This paradigm: very flexible models and lots of data requires many engineering solutions. Many modern systems require .\n",
    "\n",
    "The terrifying quote \"every time I fire a linguist my speech recognition system gets better\"\n",
    "\n",
    "https://twitter.com/yoavgo/status/1431287117553053700\n",
    "https://twitter.com/TaliaRinger/status/1494699952207011844\n",
    "https://twitter.com/j6mes/status/1141288879129059328\n",
    "\n",
    "Argues that the current paradigm - flexible models with lots of data - requires more engineering for things like scalability, efficiency, testing and debugging, etc.\n",
    "This progress requries accesibility, we need as many engineers as possible. In order to improve accessibility we need things like more cloud compute, more open source software, standardized benchmarks, etc. all things which come from engineering.\n",
    "\n",
    "Cho raises a bit of a cheeky POI: \"If the number of people equates to progress, why is the U.S. so bad at soccer?\"\n",
    "Maya's response is that it's a random function with different distributions :p\n",
    "\n",
    "We had catapults before we understood newtonian mechanics.\n",
    "We had good smallpox vaccines before we understood how antibodies work.\n",
    "We had good plant breeding before we understood genetics.\n",
    "\n",
    "It requires a phase change before we need science to push us into.\n",
    "\n",
    "Final meta-comment on the progress of AI - progress can be blocked when the public gets more worried about the negative consequences of a technology. She hopes that progress is not blocked and that we can continue to work on AI regardless of which side is right.\n",
    "\n",
    ">_I'm really not sure how to interpret this...\n",
    "\n",
    "\n",
    "#### [Pulkit Agrawal](https://people.csail.mit.edu/pulkitag/) (Member of Opposition)\n",
    "\n",
    "Imagine I had all the data, compute, and engineers, but no gradient descent. What would happen? We may engineer the heck out of random search and burn the planet trying to find a solution.\n",
    "\n",
    "Training deep neural network is a lot about engineering - but a lot of times when you're doing engineering, you're actually doing science.\n",
    "\n",
    "Even though we can't prove why SGD converges to good solutions in neural networks, we still know empirically that it works because of tons of experiments.\n",
    "This process where we run tons of experiments to guide our future decisions is exactly the scientific process.\n",
    "\n",
    "To build AI systems we don't require humans?\n",
    "What about things like fairness, transparency, and safety? In order to ensure our systems have these properties, we first need to study ourselves and our own values in order to determine what these properties entail which is science.\n",
    "To deploy AI systems we need more science _of humans_.\n",
    "\n",
    "What is intelligence? How do we judge if something is intelligence? We need science again to study what intelligence is in order to create a good definition of intelligence and science.\n",
    "\n",
    "Even here at the conference, we often compare method A to method B - if method B is better, we publish a paper on it. This is exactly science!\n",
    "\n",
    "\n",
    "Science is a guide on how to do new engineering and how to come up with breakthrough ideas.\n",
    "Einstein said if I had one hour to solve a problem I would spend 55 minutes thinking about what the question is, because once I have the question it would take me 5 minutes to find the answer.\n",
    "This is what science and engineering is.\n",
    "\n",
    "#### Sella Nevo again, on behalf of [Been Kim](https://beenkim.github.io/) (Proposition Whip)\n",
    "\n",
    "Let's review:\n",
    "A huge portion of the oppositions case is that engineering alone is not enough.\n",
    "But nobody disagrees with this.\n",
    "With no engineering there would also be no progress.\n",
    "\n",
    "Don't accept that engineering has no goal without science - the goal is to build something useful.\n",
    "_decline poi_.\n",
    "\n",
    "Science plants the seed and engineering pushes it forward - also no disagree, but what will drive AI progress going forward? Yes information theory and bayesian statistics were necessary to get to this point, but new innovations in science are not what is driving progress today.\n",
    "\n",
    "Because we are trying to do a computational version of intelligence, unlike in other fields, where the goal is to allow flexible models to create their _own innovations_, it is not necessarily true that we will need to return to scientific innovations to drive progress anymore.\n",
    "\n",
    "Lastly, disagree that breakthroughs are not being driven by science - cites GPT-3, where everything is just bigger (e.g. no ). It's humungous size is what drives the progress of GPT-3, so current breakthroughts are not due to science only.\n",
    "\n",
    "Ida POI: The breakthroughs are all based on science, the turning points are coming from science.\n",
    "Response: Not all breakthroughs are due to science, and while historically breakthroughs were due to science, more and more recently breakthroughs come from science and this pattern will continue moving forward.\n",
    "\n",
    "Moving on: Any kind of exploration that isn't random is science - the opposition finds this to be mostly semantics, e.g. they can also redefine anything that uses a computer as engineering.\n",
    "Advancing theory and letting it drive insight is meaningfully science,\n",
    "playing around with things and tweaking it is meaningfully engineering.\n",
    "\n",
    "This also addresses the carbon footprint problem - we should also be talking about efficienty, but this is a classic engineering endeavour.\n",
    "\n",
    "The last speaker started to defend that we need to understand how things work - how many advancements are actually driven by this? Very few, at least in our field. In practice, theory is lagging far behind our engineering capabilities.\n",
    "\n",
    "#### [Sujoy Ganguly](https://blog.unity.com/author/cap-sujoy-ganguly) (Opposition Whip)\n",
    "\n",
    "Sujoy begins by stressing the need to clarify the differences between.\n",
    "\n",
    "Engineering has certainly improved the democratization of this, but many people working in ML.\n",
    "Running experiments, making observations, coming up with testable hypotheses is all science, and this is what the bulk of work in machine learning is.\n",
    "\n",
    "Sella POI: \"Could you clarify what, if any, work related to AI would not be science\"\n",
    "Response: \"Creating tensorflow or pytorch is not science, doing an experiment is science\"\n",
    "\n",
    "on \"we don't need any new theoretical ideas to progress AI research\"\n",
    "Science is not only theory.\n",
    "A long history of empirical science - e.g. thermodynamics generated _laws_ first, based on empirical observations, and wasn't unified under a single theory for a while.\n",
    "\n",
    "Also refute that we don't have any need for new ideas, or new ideas coming from a scientific community.\n",
    "Contrastive learning is a new scientific concept that has recently become popular.\n",
    "Neural fields? how do we have continuous representations? We turn to a scientific representation, we don't just tackle the problem by tring to make more and more points.\n",
    "\n",
    "Scientific advancements lead to step changes.\n",
    "\n",
    "The other major point: through scientific methodologies we can set the path forward and determine _how to compare and contrast_ different methods.\n",
    "If you're basing your path forward based on empirical evidence you are using the scientific method.\n",
    "\n",
    "Sella POI: \"Can you name a single scientific innovation that has contributed to AI capabilities as much as increases in computation and data have improved LLMs capabilities?\"\n",
    "Response: \"neural networks?\"\n",
    "Sella: \"Recent?\"\n",
    "Response: \"A more recent one: neural fields - came through a scientific realization that we could model things continuously, and relied on field theory. This was a scientific idea and required new scientific thinking.\"\n",
    "\n",
    "Cont.\n",
    "The last thing to leave on - another key point.\n",
    "The ideas of fairness, transparency, accountability - we need to embed these ideas in our models in order to deploy them in the real world.\n",
    "These ideas won't come through scale - rather careful thought, good metrics, experiments and observations, which are science.\n",
    "\n",
    "\n",
    "![](blog_figs/icml2022/debate-poll.png)\n",
    "\n",
    "#### My Thoughts\n",
    "\n",
    "First, I'll note that this question pre-supposes that we even _want_ AI (which, in this context I take to mean \"general AI\" or perhaps \"human-level AI\") - I don't think that this is a trivial assumption, and would make for an interesting debate in and of itself.\n",
    "Second, I'll note that I'm extremely biased in that I despite the fact that I train neural networks and measure them on benchmarks, _I consider myself a scientist_.\n",
    "My goal in beginning a PhD has always been to understand things deeply, \n",
    "\n",
    "1. Fairness\n",
    "2. The assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Thanx 4 reeding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
